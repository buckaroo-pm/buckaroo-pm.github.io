{
  "packageName": "buckaroo-pm/cpp-taskflow",
  "name": "taskflow/taskflow",
  "licence": "MIT",
  "description": "Modern C++ Parallel Task Programming Library",
  "readme": "# Cpp-Taskflow <img align=\"right\" width=\"10%\" src=\"image/cpp-taskflow_logo.png\">\n\n[![Linux Build Status](https://travis-ci.com/cpp-taskflow/cpp-taskflow.svg?branch=master)](https://travis-ci.com/cpp-taskflow/cpp-taskflow)\n[![Windows Build status](https://ci.appveyor.com/api/projects/status/te9bjp4yfhq7f8hq?svg=true)](https://ci.appveyor.com/project/TsungWeiHuang/cpp-taskflow)\n[![Standard](image/cpp17.svg)](https://en.wikipedia.org/wiki/C%2B%2B#Standardization)\n[![Download](image/download.svg)](https://github.com/cpp-taskflow/cpp-taskflow/archive/master.zip)\n[![Wiki](image/doc-wiki.svg)][wiki]\n[![Insights](image/maintained.svg)][GitHub insights]\n[![License: MIT](./image/license_badge.svg)](./LICENSE)\n\nA fast C++ header-only library to help you quickly write parallel programs with complex task dependencies\n\n# Why Cpp-Taskflow?\n\nCpp-Taskflow is by far faster, more expressive, fewer lines of code, and easier for drop-in integration\nthan existing parallel task programming libraries such as [OpenMP Tasking][OpenMP Tasking] and Intel [TBB FlowGraph][TBB FlowGraph].\n\n![](image/performance.jpg)\n\nCpp-Taskflow enables you to implement efficient task decomposition strategies\nthat incorporate both regular loop-based parallelism \nand irregular compute patterns to optimize multicore performance.\n\n\n| Without Cpp-Taskflow | With Cpp-Taskflow |\n| -------------------- | ----------------- |\n| ![](image/profile_without_taskflow.gif) | ![](image/profile_with_taskflow.gif) |\n\nCpp-Taskflow has a unified interface for both *static* tasking and *dynamic* tasking,\nallowing users to quickly master our parallel task programming model in a natural idiom.\n\n| Static Tasking | Dynamic Tasking |\n| :------------: | :-------------: |\n| ![](image/static_graph.png) | ![](image/dynamic_graph.png) |\n\nCpp-Taskflow is committed to support both academic and industry research projects,\nmaking it reliable and cost-effective for long-term and large-scale developments.\n\n+ *\"Cpp-Taskflow is the cleanest Task API I've ever seen.\" [damienhocking][damienhocking]*\n+ *\"Cpp-Taskflow has a very simple and elegant tasking interface. The performance also scales very well.\" [totalgee][totalgee]*\n+ *\"Best poster award for open-source parallel programming library.\" [Cpp Conference 2018][Cpp Conference 2018]*\n\nSee a quick [presentation][Presentation] and \nvisit the [documentation][wiki] to learn more about Cpp-Taskflow.\n\n# Get Started with Cpp-Taskflow\n\nThe following example [simple.cpp](./example/simple.cpp) shows the basic Cpp-Taskflow API\nyou need in most applications.\n\n```cpp\n#include <taskflow/taskflow.hpp>  // Cpp-Taskflow is header-only\n\nint main(){\n  \n  tf::Taskflow tf;\n\n  auto [A, B, C, D] = tf.silent_emplace(\n    [] () { std::cout << \"TaskA\\n\"; },               //  task dependency graph\n    [] () { std::cout << \"TaskB\\n\"; },               // \n    [] () { std::cout << \"TaskC\\n\"; },               //          +---+          \n    [] () { std::cout << \"TaskD\\n\"; }                //    +---->| B |-----+   \n  );                                                 //    |     +---+     |\n                                                     //  +---+           +-v-+ \n  A.precede(B);  // A runs before B                  //  | A |           | D | \n  A.precede(C);  // A runs before C                  //  +---+           +-^-+ \n  B.precede(D);  // B runs before D                  //    |     +---+     |    \n  C.precede(D);  // C runs before D                  //    +---->| C |-----+    \n                                                     //          +---+          \n  tf.wait_for_all();  // block until finish\n\n  return 0;\n}\n```\n\nCompile and run the code with the following commands:\n\n```bash\n~$ g++ simple.cpp -std=c++1z -O2 -lpthread -o simple\n~$ ./simple\nTaskA\nTaskC  <-- concurrent with TaskB\nTaskB  <-- concurrent with TaskC\nTaskD\n```\n\nIt is clear now Cpp-Taskflow is powerful in parallelizing tasks with complex dependencies.\nThe following example demonstrates a concurrent execution of 10 tasks with 15 dependencies.\nWith Cpp-Taskflow, you only need ***15 lines of code***.\n\n<img align=\"right\" src=\"image/complex.png\" width=\"30%\">\n\n```cpp\n// source dependencies\nS.precede(a0);    // S runs before a0\nS.precede(b0);    // S runs before b0\nS.precede(a1);    // S runs before a1\n\n// a_ -> others\na0.precede(a1);   // a0 runs before a1\na0.precede(b2);   // a0 runs before b2\na1.precede(a2);   // a1 runs before a2\na1.precede(b3);   // a1 runs before b3\na2.precede(a3);   // a2 runs before a3\n\n// b_ -> others\nb0.precede(b1);   // b0 runs before b1\nb1.precede(b2);   // b1 runs before b2\nb2.precede(b3);   // b2 runs before b3\nb2.precede(a3);   // b2 runs before a3\n\n// target dependencies\na3.precede(T);    // a3 runs before T\nb1.precede(T);    // b1 runs before T\nb3.precede(T);    // b3 runs before T\n```\n\n# Create a Taskflow Graph\n\nCpp-Taskflow has very expressive and neat methods to create dependency graphs.\nMost applications are developed through the following three steps.\n\n## Step 1: Create a Task\n\nA task is a callable object for which [std::invoke][std::invoke] is applicable.\nCreate a taskflow object to start a task dependency graph.\n\n```cpp\ntf::Taskflow tf;\n```\n\nCreate a task from a callable object via the method `silent_emplace`\nto get a task handle.\n\n```cpp\nauto A = tf.silent_emplace([](){ std::cout << \"Task A\\n\"; });\n```\n\nYou can create multiple tasks at one time.\n\n```cpp\nauto [A, B, C, D] = tf.silent_emplace(\n  [] () { std::cout << \"Task A\\n\"; },\n  [] () { std::cout << \"Task B\\n\"; },\n  [] () { std::cout << \"Task C\\n\"; },\n  [] () { std::cout << \"Task D\\n\"; }\n);\n```\n\n## Step 2: Define Task Dependencies\n\nOnce tasks are created in the pool, you need to specify task dependencies in a \n[Directed Acyclic Graph (DAG)](https://en.wikipedia.org/wiki/Directed_acyclic_graph) fashion.\nThe handle `Task` supports different methods for you to describe task dependencies.\n\n**Precede**: Adding a preceding link forces one task to run ahead of one another.\n```cpp\nA.precede(B);  // A runs before B.\n```\n\n**Gather**: Adding a gathering link forces one task to run after other(s).\n```cpp\nA.gather(B);  // A runs after B\n```\n\n## Step 3: Execute the Tasks\n\nThere are three methods to execute a task dependency graph, \n`dispatch`, `silent_dispatch`, and `wait_for_all`.\n\n```cpp\nauto future = tf.dispatch();  // non-blocking, returns with a future immediately.\ntf.silent_dispatch();         // non-blocking, no return\n```\n\nCalling `wait_for_all` will block until all tasks complete.\n\n```cpp\ntf.wait_for_all();\n```\n\nEach of these methods dispatches the current graph to threads for execution\nand create a data structure called *topology* to store the execution status.\n\n\n# Dynamic Tasking\n\nAnother powerful feature of Taskflow is *dynamic* tasking.\nA dynamic task is created during the execution of a dispatched taskflow graph, i.e.,\ntopology.\nThese tasks are spawned by a parent task and are grouped together to a *subflow* graph.\nThe example below demonstrates how to create a subflow\nthat spawns three tasks during its execution.\n\n<img align=\"right\" src=\"image/subflow_join.png\" width=\"40%\">\n\n```cpp\n// create three regular tasks\nauto A = tf.silent_emplace([](){}).name(\"A\");\nauto C = tf.silent_emplace([](){}).name(\"C\");\nauto D = tf.silent_emplace([](){}).name(\"D\");\n\n// create a subflow graph (dynamic tasking)\nauto B = tf.silent_emplace([] (auto& subflow) {\n  auto B1 = subflow.silent_emplace([](){}).name(\"B1\");\n  auto B2 = subflow.silent_emplace([](){}).name(\"B2\");\n  auto B3 = subflow.silent_emplace([](){}).name(\"B3\");\n  B1.precede(B3);\n  B2.precede(B3);\n}).name(\"B\");\n            \nA.precede(B);  // B runs after A \nA.precede(C);  // C runs after A \nB.precede(D);  // D runs after B \nC.precede(D);  // D runs after C \n\n// execute the graph without cleanning up topologies\ntf.dispatch().get();\nstd::cout << tf.dump_topologies();\n```\n\nBy default, a subflow graph joins to its parent node. \nThis guarantees a subflow graph to finish before the successors of \nits parent node.\nYou can disable this feature by calling `subflow.detach()`.\nDetaching the above subflow will result in the following execution flow.\n\n<img align=\"right\" src=\"image/subflow_detach.png\" width=\"65%\">\n\n```cpp\n// detach a subflow graph\n[] (auto& subflow) {\n  ...\n  B1.precede(B3);\n  B2.precede(B3);\n\n  // detach from B \n  subflow.detach();\n}).name(\"TaskB\");\n```\n\n## Step 1: Create a Subflow\n\nCpp-Taskflow has an unified interface for static and dynamic tasking.\nTo create a subflow for dynamic tasking, \nemplace a callable on one argument of type `tf::SubflowBuilder`.\n\n```cpp\nauto A = tf.silent_emplace([] (tf::SubflowBuilder& subflow) {});\n```\n\nSimilarly, you can get a [std::future][std::future] object to the execution status of the subflow.\n\n```cpp\nauto [A, fu] = tf.emplace([] (tf::SubflowBuilder& subflow) {});\n```\n\nA subflow builder is a lightweight object that allows you to create \narbitrary dependency graphs on the fly.\nAll graph building methods defined in taskflow\ncan be used in a subflow builder.\n\n```cpp\nauto A = tf.silent_emplace([] (tf::SubflowBuilder& subflow) {\n  std::cout << \"Task A is spawning two subtasks A1 and A2\" << '\\n';\n  auto [A1, A2] = subflow.silent_emplace(\n    [] () { std::cout << \"subtask A1\" << '\\n'; },\n    [] () { std::cout << \"subtask A2\" << '\\n'; }\n    A1.precede(A2);\n  );\n});\n```\n\nA subflow can also be nested or recursive. You can create another subflow from\nthe execution of a subflow and so on.\n\n<img align=\"right\" src=\"image/nested_subflow.png\" width=\"45%\">\n\n```cpp\nauto A = tf.silent_emplace([] (auto& sbf){\n  std::cout << \"A spawns A1 & subflow A2\\n\";\n  auto A1 = sbf.silent_emplace([] () { \n    std::cout << \"subtask A1\\n\"; \n  }).name(\"A1\");\n\n  auto A2 = sbf.silent_emplace([] (auto& sbf2){\n    std::cout << \"A2 spawns A2_1 & A2_2\\n\";\n    auto A2_1 = sbf2.silent_emplace([] () { \n      std::cout << \"subtask A2_1\\n\"; \n    }).name(\"A2_1\");\n    auto A2_2 = sbf2.silent_emplace([] () { \n      std::cout << \"subtask A2_2\\n\"; \n    }).name(\"A2_2\");\n    A2_1.precede(A2_2);\n  }).name(\"A2\");\n  A1.precede(A2);\n}).name(\"A\");\n```\n\n## Step 2: Detach or Join a Subflow\n\nA subflow has no methods to dispatch its tasks.\nInstead, a subflow will be executed after leaving the context of the callable.\nBy default, a subflow joins to its parent task.\nDepending on applications, you can detach a subflow to enable more parallelism.\n\n```cpp\nauto A = tf.silent_emplace([] (tf::SubflowBuilder& subflow) {\n  subflow.detach();  // detach this subflow from its parent task A\n});  // subflow starts to run after the callable scope\n```\n\nDetaching or Joining a subflow has different meaning in the ready status of \nthe future object referred to it.\nIn a joined subflow, \nthe completion of its parent node is defined as when all tasks\ninside the subflow (possibly nested) finish.\n\n<img align=\"right\" src=\"image/joined_subflow_future.png\" width=\"40%\">\n\n```cpp\nint value {0};\n\n// create a joined subflow\nauto [A, fuA] = tf.emplace([&] (auto& subflow) {\n  subflow.silent_emplace([&]() { \n    value = 10; \n  });\n  return 100;   // some arbitrary value\n});\n\n// create a task B after A\nauto B = tf.silent_emplace([&] () { \n  assert(value == 10); \n  assert(fuA.wait_for(0s) == std::future_status::ready);\n});\n\n// A1 must finish before A and therefore before B\nA.precede(B);\n```\n\nWhen a subflow is detached from its parent task, it becomes a parallel\nexecution line to the current flow graph and will eventually\njoin to the same topology.\n\n<img align=\"right\" src=\"image/detached_subflow_future.png\" width=\"40%\">\n\n```cpp\nint value {0};\n\n// create a detached subflow\nauto [A, fuA] = tf.emplace([&] (auto& subflow) {\n  subflow.silent_emplace([&]() { value = 10; });\n  subflow.detach();\n  return 100;   // some arbitrary value\n});\n\n// create a task B after A\nauto B = tf.silent_emplace([&] () { \n  // no guarantee for value to be 10 nor fuA ready\n});\nA.precede(B);\n```\n\n\n# Debug a Taskflow Graph\n\nConcurrent programs are notoriously difficult to debug.\nCpp-Taskflow leverages the graph properties to relieve the debugging pain.\nTo debug a taskflow graph,\n(1) name tasks and dump the graph, and\n(2) start with one thread before going multiple.\nCurrently, Cpp-Taskflow supports [GraphViz][GraphViz] format.\n\n## Dump the Present Taskflow Graph\n\nEach time you create a task or add a dependency, \nit adds a node or an edge to the present taskflow graph.\nThe graph is not dispatched yet and you can dump it to a GraphViz format.\n\n```cpp\n// debug.cpp\ntf::Taskflow tf(0);  // use only the master thread\nauto A = tf.silent_emplace([] () {}).name(\"A\");\nauto B = tf.silent_emplace([] () {}).name(\"B\");\nauto C = tf.silent_emplace([] () {}).name(\"C\");\nauto D = tf.silent_emplace([] () {}).name(\"D\");\nauto E = tf.silent_emplace([] () {}).name(\"E\");\n\nA.precede(B, C, E); \nC.precede(D);\nB.precede(D, E); \n\nstd::cout << tf.dump();\n```\n\nRun the program and inspect whether dependencies are expressed in the right way. \nThere are a number of free [GraphViz tools][AwesomeGraphViz] you could find online\nto visualize your Taskflow graph.\n\n<img align=\"right\" src=\"image/graphviz.png\" width=\"25%\">\n\n```bash\n~$ ./debug\n\n// Taskflow with five tasks and six dependencies\ndigraph Taskflow {\n  \"A\" -> \"B\"\n  \"A\" -> \"C\"\n  \"A\" -> \"E\"\n  \"B\" -> \"D\"\n  \"B\" -> \"E\"\n  \"C\" -> \"D\"\n}\n```\n\n## Dump the Dispatched Graphs\n\nWhen you have dynamic tasks (subflows),\nyou cannot simply use the `dump` method because it displays only the static portion.\nInstead, you need to execute the graph first to include dynamic tasks\nand then use the `dump_topologies` method.\n\n<img align=\"right\" src=\"image/debug_subflow.png\" width=\"40%\">\n\n```cpp\ntf::Taskflow tf(0);  // use only the master thread\n\nauto A = tf.silent_emplace([](){}).name(\"A\");\n\n// create a subflow of two tasks B1->B2\nauto B = tf.silent_emplace([] (auto& subflow) {\n  auto B1 = subflow.silent_emplace([](){}).name(\"B1\");\n  auto B2 = subflow.silent_emplace([](){}).name(\"B2\");\n  B1.precede(B2);\n}).name(\"B\");\n\nA.precede(B);\n\n// dispatch the graph without cleanning up topologies\ntf.dispatch().get();\n\n// dump the entire graph (including dynamic tasks)\nstd::cout << tf.dump_topologies();\n```\n\n# API Reference\n\n## Taskflow API\n\nThe class `tf::Taskflow` is the main place to create and execute task dependency graph.\nThe table below summarizes a list of commonly used methods.\nVisit [documentation][wiki] to see the complete list.\n\n| Method   | Argument  | Return  | Description |\n| -------- | --------- | ------- | ----------- |\n| Taskflow | none      | none    | construct a taskflow with the worker count equal to max hardware concurrency |\n| Taskflow | size      | none    | construct a taskflow with a given number of workers |\n| emplace  | callables | tasks, futures | insert nodes to execute the given callables; results can be retrieved from the returned futures |\n| silent_emplace  | callables | tasks         | insert nodes to execute the given callables |\n| placeholder     | none        | task         | insert a node without any work; work can be assigned later |\n| linearize       | task list   | none         | create a linear dependency in the given task list |\n| parallel_for    | beg, end, callable, group | task pair | apply the callable in parallel and group-by-group to the result of dereferencing every iterator in the range | \n| parallel_for    | beg, end, step, callable, group | task pair | apply the callable in parallel and group-by-group to a index-based range | \n| reduce | beg, end, res, bop | task pair | reduce a range of elements to a single result through a binary operator | \n| transform_reduce | beg, end, res, bop, uop | task pair | apply a unary operator to each element in the range and reduce them to a single result through a binary operator | \n| dispatch        | none        | future | dispatch the current graph and return a shared future to block on completion |\n| silent_dispatch | none        | none | dispatch the current graph | \n| wait_for_all    | none        | none | dispatch the current graph and block until all graphs finish, including all previously dispatched ones, and then clear all graphs |\n| wait_for_topologies | none    | none | block until all dispatched graphs (topologies) finish, and then clear these graphs |\n| num_nodes       | none        | size | query the number of nodes in the current graph |  \n| num_workers     | none        | size | query the number of working threads in the pool |  \n| num_topologies  | none        | size | query the number of dispatched graphs |\n| dump            | none        | string | dump the current graph to a string of GraphViz format |\n| dump_topologies | none        | string | dump dispatched topologies to a string of GraphViz format |\n\n### *emplace/silent_emplace/placeholder*\n\nThe main different between `emplace` and `silent_emplace` is the return value.\nThe method `emplace` gives you a [std::future][std::future] object to retrieve the result of the callable \nwhen the task completes.\n\n```cpp\n// create a task through emplace\nauto [task, future] = tf.emplace([](){ return 1; });\ntf.wait_for_all();\nassert(future.get() == 1);\n```\n\nIf you don't care the return result, using `silent_emplace` to create a task can give you slightly better performance.\n```cpp\n// create a task through silent_emplace\nauto task = tf.emplace([](){ return; });\ntf.wait_for_all();\n```\n\nWhen task cannot be determined beforehand, you can create a placeholder and assign the calalble later.\n```cpp\n// create a placeholder and use it to build dependency\nauto A = tf.silent_emplace([](){});\nauto B = tf.placeholder();\nA.precede(B);\n\n// assign the callable later in the control flow\nB.work([](){ /* do something */ });\n```\n\n### *linearize*\n\nThe method `linearize` lets you add a linear dependency between each adjacent pair of a task sequence.\n\n<img align=\"right\" width=\"40%\" src=\"image/linearize.png\">\n\n```cpp\n// linearize five tasks\ntf.linearize(A, B, C, D);\n```\n\n### *parallel_for*\n\nThe method `parallel_for` creates a subgraph that applies the callable to each item in the given range of\na container.\n\n<img align=\"right\" width=\"40%\" src=\"image/parallel_for.png\">\n\n```cpp\n// apply callable to each container item in parallel\nauto v = {'A', 'B', 'C', 'D'};\nauto [S, T] = tf.parallel_for(\n  v.begin(),    // beg of range\n  v.end(),      // end of range\n  [] (int i) { \n    std::cout << \"parallel in \" << i << '\\n';\n  }\n);\n// add dependencies via S and T.\n```\n\nChanging the group size can force intra-group tasks to run sequentially\nand inter-group tasks to run in parallel.\nDepending on applications, different group sizes can result in significant performance hit.\n\n<img align=\"right\" width=\"20%\" src=\"image/parallel_for_2.png\">\n\n```cpp\n// apply callable to two container items at a time in parallel\nauto v = {'A', 'B', 'C', 'D'};\nauto [S, T] = tf.parallel_for(\n  v.begin(),    // beg of range\n  v.end(),      // end of range\n  [] (int i) { \n    std::cout << \"AB and CD run in parallel\" << '\\n';\n  },\n  2  // group two tasks at a time\n);\n```\n\nBy default, taskflow performs an even partition over worker threads\nif the group size is not specified (or equal to 0).\n\nIn addition to range-based iterator, parallel\\_for has another overload on an index-based loop.\nThe first three argument to this overload indicates \nstarting index, ending index (exclusive), and step size.\n\n```cpp\n// [0, 10) with a step size of 2\nauto [S, T] = tf.parallel_for(\n  0, 10, 2, \n  [] (int i) {\n    std::cout << \"parallel_for on index \" << i << std::endl;\n  }, \n  2  // group two tasks at a time\n);\n// will print 0, 2, 4, 6, 8 (three groups, {0, 2}, {4, 6}, {8})\n```\n\nYou can also go opposite direction by reversing the starting index and the ending index\nwith a negative step size.\n\n```cpp\n// [10, 0) with a step size of -2\nauto [S, T] = tf.parallel_for(\n  10, 0, 2, \n  [] (int i) {\n    std::cout << \"parallel_for on index \" << i << std::endl;\n  }\n);\n// will print 10, 8, 6, 4, 2 (group size decided by taskflow)\n```\n\n### *reduce/transform_reduce*\n\nThe method `reduce` creates a subgraph that applies a binary operator to a range of items.\nThe result will be stored in the referenced `res` object passed to the method. \nIt is your responsibility to assign it a correct initial value to reduce.\n\n<img align=\"right\" width=\"45%\" src=\"image/reduce.png\">\n\n```cpp\nauto v = {1, 2, 3, 4}; \nint sum {0};\nauto [S, T] = tf.reduce(    // for example, 2 threads\n  v.begin(), v.end(), sum, std::plus<int>()\n);  \n```\n\nThe method `transform_reduce` is similar to reduce, except it applies a unary operator before reduction.\nThis is particular useful when you need additional data processing to reduce a range of elements.\n\n```cpp\nstd::vector<std::pari<int, int>> v = { {1, 5}, {6, 4}, {-6, 4} };\nint min = std::numeric_limits<int>::max();\nauto [S, T] = tf.transform_reduce(v.begin(), v.end(), min, \n  [] (int l, int r) { return std::min(l, r); },\n  [] (const std::pair<int, int>& pair) { return std::min(p.first, p.second); }\n);\n```\n\nBy default, all reduce methods distribute the workload evenly across threads.\n\n### *dispatch/silent_dispatch/wait_for_topologies/wait_for_all*\n\nDispatching a taskflow graph will schedule threads to execute the current graph and return immediately.\nThe method `dispatch` gives you a [std::future][std::future] object to probe the execution progress while\n`silent_dispatch` doesn't.\n\n```cpp\nauto future = tf.dispatch();\n// do something else to overlap with the execution \n// ...\nstd::cout << \"now I need to block on completion\" << '\\n';\nfuture.get();\nstd::cout << \"all tasks complete\" << '\\n';\n```\n\nIf you need to block your program flow until all tasks finish \n(including the present taskflow graph), use `wait_for_all` instead.\n\n```cpp\ntf.wait_for_all();\nstd::cout << \"all tasks complete\" << '\\n';\n```\n\nIf you only need to block your program flow until all dispatched taskflow graphs finish,\nuse `wait_for_topologies`.\n\n```cpp\ntf.wait_for_topologies();\nstd::cout << \"all topologies complete\" << '\\n';\n```\n\n## Task API\n\nEach time you create a task, the taskflow object adds a node to the present task dependency graph\nand return a *task handle* to you.\nA task handle is a lightweight object that defines a set of methods for users to\naccess and modify the attributes of the associated task.\nThe table below summarizes the list of commonly used methods.\nVisit [documentation][wiki] to see the complete list.\n\n| Method         | Argument    | Return | Description |\n| -------------- | ----------- | ------ | ----------- |\n| name           | string      | self   | assign a human-readable name to the task |\n| work           | callable    | self   | assign a work of a callable object to the task |\n| precede        | task        | self   | enable this task to run *before* the given task |\n| gather         | task list   | self   | enable this task to run *after* the given tasks |\n| num_dependents | none        | size   | return the number of dependents (inputs) of this task |\n| num_successors | none        | size   | return the number of successors (outputs) of this task |\n\n### *name*\n\nThe method `name` lets you assign a human-readable string to a task.\n\n```cpp\nA.name(\"my name is A\");\n```\n\n### *work*\n\nThe method `work` lets you assign a callable to a task.\n\n```cpp\nA.work([] () { std::cout << \"hello world!\"; });\n```\n\n### *precede*\n\nThe method `precede` is the basic building block to add a precedence between two tasks.\n\n<img align=\"right\" width=\"20%\" src=\"image/precede.png\">\n\n```cpp\n// make A runs before B\nA.precede(B);\n```\n\nYou can precede multiple tasks at one time.\n\n<img align=\"right\" width=\"30%\" src=\"image/broadcast.png\">\n\n```cpp\n// make A run before B, C, D, and E\n// B, C, D, and E run in parallel\nA.precede(B, C, D, E);\n```\n\n### *gather*\n\nThe method `gather` lets you add multiple precedences to a task.\n\n<img align=\"right\" width=\"30%\" src=\"image/gather.png\">\n\n```cpp\n// B, C, D, and E run in parallel\n// A runs after B, C, D, and E complete\nA.gather(B, C, D, E);\n```\n\n# Caveats\n\nWhile Cpp-Taskflow enables the expression of very complex task dependency graph that might contain \nthousands of task nodes and links, there are a few amateur pitfalls and mistakes to be aware of.\n\n+ Having a cycle in a graph may result in running forever\n+ Trying to modify a dispatched task can result in undefined behavior\n+ Touching a taskflow from multiple threads are not safe\n\nCpp-Taskflow is known to work on Linux distributions, MAC OSX, and Microsoft Visual Studio.\nPlease [let me know][email me] if you found any issues in a particular platform.\n\n# System Requirements\n\nTo use Cpp-Taskflow, you only need a [C++17][C++17] compiler:\n+ GNU C++ Compiler v7.3 with -std=c++1z\n+ Clang C++ Compiler v6.0 with -std=c++17\n+ Microsoft Visual Studio Version 15.7 (MSVC++ 19.14)\n\n# Compile Unit Tests and Examples\n\nCpp-Taskflow uses [CMake](https://cmake.org/) to build examples and unit tests.\nWe recommend using out-of-source build.\n\n```bash\n~$ cmake --version  # must be at least 3.9 or higher\n~$ mkdir build\n~$ cd build\n~$ cmake ../\n~$ make \n```\n\n## Unit Tests\n\nCpp-Taskflow uses [Doctest](https://github.com/onqtam/doctest) for unit tests.\n\n```bash\n~$ ./unittest/taskflow\n```\n\nAlternatively, you can use CMake's testing framework to run the unittest.\n\n```bash\n~$ cd build\n~$ make test\n```\n\n## Examples\n\nThe folder `example/` contains several examples and is a great place to learn to use Cpp-Taskflow.\n\n| Example |  Description |\n| ------- |  ----------- | \n| [simple.cpp](./example/simple.cpp) | uses basic task building blocks to create a trivial taskflow  graph |\n| [debug.cpp](./example/debug.cpp)| inspects a taskflow through the dump method |\n| [emplace.cpp](./example/emplace.cpp)| demonstrates the difference between the emplace method and the silent_emplace method |\n| [matrix.cpp](./example/matrix.cpp) | creates two set of matrices and multiply each individually in parallel |\n| [dispatch.cpp](./example/dispatch.cpp) | demonstrates how to dispatch a task dependency graph and assign a callback to execute |\n| [multiple_dispatch.cpp](./example/multiple_dispatch.cpp) | illustrates dispatching multiple taskflow graphs as independent batches (which all run on the same threadpool) |\n| [parallel_for.cpp](./example/parallel_for.cpp)| parallelizes a for loop with unbalanced workload |\n| [reduce.cpp](./example/reduce.cpp)| performs reduce operations over linear containers |\n| [subflow.cpp](./example/subflow.cpp)| demonstrates how to create a subflow graph that spawns three dynamic tasks |\n| [threadpool.cpp](./example/threadpool.cpp)| benchmarks different threadpool implementations |\n| [threadpool_cxx14.cpp](./example/threadpool_cxx14.cpp)| shows use of the C++14-compatible threadpool implementation, which may be used when you have no inter-task (taskflow) dependencies to express |\n| [taskflow.cpp](./example/taskflow.cpp)| benchmarks taskflow on different task dependency graphs |\n| [executor.cpp](./example/executor.cpp)| shows how to create multiple taskflow objects sharing one executor to avoid the thread over-subscription problem |\n\n# Get Involved\n\n+ Report bugs/issues by submitting a [GitHub issue][GitHub issues]\n+ Submit contributions using [pull requests][GitHub pull requests]\n+ Learn more about Cpp-Taskflow by reading the [documentation][wiki]\n\n# Who is Using Cpp-Taskflow?\n\nCpp-Taskflow is being used in both industry and academic projects to scale up existing workloads \nthat incorporate complex task dependencies. \n\n- [OpenTimer][OpenTimer]: A High-performance Timing Analysis Tool for Very Large Scale Integration (VLSI) Systems\n- [DtCraft][DtCraft]: A General-purpose Distributed Programming Systems using Data-parallel Streams\n- [Firestorm][Firestorm]: Fighting Game Engine with Asynchronous Resource Loaders (developed by [ForgeMistress][ForgeMistress])\n- [Shiva][Shiva]: An extensible engine via an entity component system through scripts, DLLs, and header-only (C++)\n\nPlease [let me know][email me] if I forgot your project!\n\n# Contributors\n\nCpp-Taskflow is being actively developed and contributed by the following people:\n\n- [Tsung-Wei Huang][Tsung-Wei Huang] created the Cpp-Taskflow project and implemented the core routines\n- [Chun-Xun Lin][Chun-Xun Lin] co-created the Cpp-Taskflow project and implemented the core routines\n- [Martin Wong][Martin Wong] supported the Cpp-Taskflow project through NSF and DARPA funding\n- [Andreas Olofsson][Andreas Olofsson] supported the Cpp-Taskflow project through the DARPA IDEA project\n- [Nan Xiao](https://github.com/NanXiao) fixed compilation error of unittest on the Arch platform\n- [Vladyslav](https://github.com/innermous) fixed comment errors in README.md and examples\n- [vblanco20-1](https://github.com/vblanco20-1) fixed compilation error on Microsoft Visual Studio\n- [Glen Fraser](https://github.com/totalgee) created a standalone C++14-compatible [threadpool](./taskflow/threadpool/threadpool_cxx14.hpp) for taskflow; various other fixes and examples\n- [Guannan Guo](https://github.com/gguo4) added different threadpool implementations to enhance the performance for taskflow\n- [Patrik Huber][Patrik Huber] helped fixed typos in the documentation\n- [ForgeMistress][ForgeMistress] provided API ideas about sharing the executor to avoid thread over-subscriptiong issues\n- [Alexander Neumann](https://github.com/Neumann-A) helped modify the cmake build to make Cpp-Taskflow importable from external cmake projects\n\nMeanwhile, we appreciate the support from many organizations for our development on Cpp-Taskflow.\nPlease [let me know][email me] if I forgot someone!\n\n| [<img src=\"image/uiuc.png\" width=\"100px\">][UIUC] | [<img src=\"image/csl.png\" width=\"100px\">][CSL] | [<img src=\"image/nsf.png\" width=\"100px\">][NSF] | [<img src=\"image/darpa.png\" width=\"100px\">][DARPA IDEA] |\n| :---: | :---: | :---: | :---: |\n\n\n\n# License\n\nCpp-Taskflow is licensed under the [MIT License](./LICENSE).\n\n* * *\n\n[Tsung-Wei Huang]:       https://twhuang.ece.illinois.edu/\n[Chun-Xun Lin]:          https://github.com/clin99\n[Martin Wong]:           https://ece.illinois.edu/directory/profile/mdfwong\n[Andreas Olofsson]:      https://github.com/aolofsson\n[Gitter]:                https://gitter.im/cpp-taskflow/Lobby\n[Gitter badge]:          ./image/gitter_badge.svg\n[GitHub releases]:       https://github.com/coo-taskflow/cpp-taskflow/releases\n[GitHub issues]:         https://github.com/cpp-taskflow/cpp-taskflow/issues\n[GitHub insights]:       https://github.com/cpp-taskflow/cpp-taskflow/pulse\n[GitHub pull requests]:  https://github.com/cpp-taskflow/cpp-taskflow/pulls\n[GraphViz]:              https://www.graphviz.org/\n[AwesomeGraphViz]:       https://github.com/CodeFreezr/awesome-graphviz\n[OpenMP Tasking]:        http://www.nersc.gov/users/software/programming-models/openmp/openmp-tasking/\n[TBB FlowGraph]:         https://www.threadingbuildingblocks.org/tutorial-intel-tbb-flow-graph\n[OpenTimer]:             https://github.com/OpenTimer/OpenTimer\n[DtCraft]:               http://dtcraft.web.engr.illinois.edu/\n[totalgee]:              https://github.com/totalgee\n[damienhocking]:         https://github.com/damienhocking\n[ForgeMistress]:         https://github.com/ForgeMistress\n[Patrik Huber]:          https://github.com/patrikhuber\n[DARPA IDEA]:            https://www.darpa.mil/news-events/2017-09-13\n[NSF]:                   https://www.nsf.gov/\n[UIUC]:                  https://illinois.edu/\n[CSL]:                   https://csl.illinois.edu/\n[wiki]:                  https://cpp-taskflow.github.io/cpp-taskflow/index.html\n[PayMe]:                 https://www.paypal.me/twhuang/10\n[C++17]:                 https://en.wikipedia.org/wiki/C%2B%2B17\n[email me]:              mailto:twh760812@gmail.com\n[Cpp Conference 2018]:   https://github.com/CppCon/CppCon2018\n\n[std::invoke]:           https://en.cppreference.com/w/cpp/utility/functional/invoke\n[std::future]:           https://en.cppreference.com/w/cpp/thread/future\n\n[Firestorm]:             https://github.com/ForgeMistress/Firestorm\n[Shiva]:                 https://shiva.gitbook.io/project/shiva\n\n[Presentation]:          https://cpp-taskflow.github.io/\n\n\n",
  "versions": [],
  "updated": "2020-05-04T16:56:48Z",
  "updatedUpstream": "2021-01-13T19:55:52Z",
  "contributors": [
    {
      "login": "arun11299",
      "avatarUrl": "https://avatars0.githubusercontent.com/u/214426?u=83c959708aca505936c771b3ab3c98a602579d62&v=4"
    },
    {
      "login": "totalgee",
      "avatarUrl": "https://avatars2.githubusercontent.com/u/306082?v=4"
    },
    {
      "login": "iplayfast",
      "avatarUrl": "https://avatars2.githubusercontent.com/u/751306?u=6154aec048f07c938f7256877f43765a0adb7634&v=4"
    },
    {
      "login": "SamuelMarks",
      "avatarUrl": "https://avatars1.githubusercontent.com/u/807580?u=163debc9c32e7086f42128064501f6075a5c771e&v=4"
    },
    {
      "login": "musteresel",
      "avatarUrl": "https://avatars2.githubusercontent.com/u/912651?v=4"
    },
    {
      "login": "xgdgsc",
      "avatarUrl": "https://avatars1.githubusercontent.com/u/1189869?v=4"
    },
    {
      "login": "vblanco20-1",
      "avatarUrl": "https://avatars3.githubusercontent.com/u/1417000?v=4"
    },
    {
      "login": "tjhei",
      "avatarUrl": "https://avatars2.githubusercontent.com/u/1531285?u=c46170e7d7c82d85441043632f00c502fb540db3&v=4"
    },
    {
      "login": "leokolln",
      "avatarUrl": "https://avatars2.githubusercontent.com/u/1807853?u=e71f9af16ee5bab62eabd3ea0c2463b79345e117&v=4"
    },
    {
      "login": "NanXiao",
      "avatarUrl": "https://avatars1.githubusercontent.com/u/2338189?u=50478039e7023a74d21a235ff834a3ff655a9fe2&v=4"
    },
    {
      "login": "matt77hias",
      "avatarUrl": "https://avatars0.githubusercontent.com/u/2464019?v=4"
    },
    {
      "login": "corporateshark",
      "avatarUrl": "https://avatars2.githubusercontent.com/u/2510143?u=de3596226340b359d2dca1475ac1e452f33618f9&v=4"
    },
    {
      "login": "patrikhuber",
      "avatarUrl": "https://avatars3.githubusercontent.com/u/4967343?u=a9baad289285da38364dfc4971351f01ab968ff7&v=4"
    },
    {
      "login": "vtronko",
      "avatarUrl": "https://avatars2.githubusercontent.com/u/8950786?u=188e0fb06514a9a9e2dd4c9646e0f5bf11faa0c2&v=4"
    },
    {
      "login": "Croolman",
      "avatarUrl": "https://avatars1.githubusercontent.com/u/8963977?u=f1b6f859402e298130c0354fc884d0af5d4cacf7&v=4"
    },
    {
      "login": "Levi-Armstrong",
      "avatarUrl": "https://avatars2.githubusercontent.com/u/9803128?u=f6e9c208021299989b6d8a27c8cf60e69c3340ac&v=4"
    },
    {
      "login": "remz1337",
      "avatarUrl": "https://avatars0.githubusercontent.com/u/9980037?u=2c686e855b1288b5d00894f79961cb056d68e0d9&v=4"
    },
    {
      "login": "netcan",
      "avatarUrl": "https://avatars1.githubusercontent.com/u/11377070?u=a2c15d68fabc306aee2f5bb156dcd9b82aac7278&v=4"
    },
    {
      "login": "mpowelson",
      "avatarUrl": "https://avatars0.githubusercontent.com/u/12128406?v=4"
    },
    {
      "login": "tsung-wei-huang",
      "avatarUrl": "https://avatars0.githubusercontent.com/u/13237509?u=3f41067960daea532c5f8c4d0fed179982cb5c02&v=4"
    },
    {
      "login": "dian-lun-lin",
      "avatarUrl": "https://avatars3.githubusercontent.com/u/14581032?u=35b04aff81844594e08b875e05a28eb1de7a8abb&v=4"
    },
    {
      "login": "Ubpa",
      "avatarUrl": "https://avatars1.githubusercontent.com/u/15104079?u=8f9636871c42da051cbac6df7a28e206d6a8676c&v=4"
    },
    {
      "login": "MambaWong",
      "avatarUrl": "https://avatars2.githubusercontent.com/u/16932438?u=c21836c32277772fe32ecbb2cdae52915180c1b3&v=4"
    },
    {
      "login": "gzz2000",
      "avatarUrl": "https://avatars1.githubusercontent.com/u/19143357?v=4"
    },
    {
      "login": "soonho-tri",
      "avatarUrl": "https://avatars0.githubusercontent.com/u/20779767?u=608da8ce5f4be3ce52b6153b3caf3c8bbda5a750&v=4"
    }
  ],
  "fundingLinks": [
    "https://github.com/taskflow"
  ],
  "contactLinks": [],
  "stars": 4778,
  "forks": 548,
  "topics": [
    "parallel-programming",
    "threadpool",
    "concurrent-programming",
    "high-performance-computing",
    "multicore-programming",
    "multi-threading",
    "taskparallelism",
    "multithreading",
    "parallel-computing",
    "work-stealing",
    "gpu-programming",
    "heterogeneous-parallel-programming",
    "cuda-programming",
    "cuda",
    "gpgpu"
  ]
}